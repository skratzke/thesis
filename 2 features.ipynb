{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb365156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os \n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d0461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              title              author  \\\n",
      "0  The Mysterious Disappearance of Leon I Mean Noel       Raskin, Ellen   \n",
      "1         The Summer I Turned Pretty The Collection        Han, Jenny *   \n",
      "2                       Complete Me Stark Trilogy 3        Kenner, J. *   \n",
      "3         One More Chance Rosemary Beach 8 Chance 2      Glines, Abbi *   \n",
      "4                 Sign Off Caught Dead in Wyoming 1  McLinn, Patricia *   \n",
      "\n",
      "                     fmc_name  \n",
      "0               Mrs. Carillon  \n",
      "1               Belly Conklin  \n",
      "2                       Nikki  \n",
      "3              Harlow Manning  \n",
      "4  Elizabeth 'E. M.' Danniher  \n"
     ]
    }
   ],
   "source": [
    "df_fmc = pd.read_csv(\"df_fmc.csv\")\n",
    "df_fmc = df_fmc[['title', 'author', 'fmc_name']]\n",
    "print(df_fmc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6b7794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are a helpful literary assistant. Your job is to search the internet and assess several aspects for books that are provided to you.\n",
    "\n",
    "    You return a Python list for each book, where each element is the answer to a question. The list always needs to have exactly 27 elements.\n",
    "    Most of the questions are about a female major character of the book whose name will be provided alongside the book title. \n",
    "    For all questions about the female character, consider any occurrence of the trait or behavior at any point in the book.\n",
    "\n",
    "    1. What's the gender of the author? (0 = male, 1 = female)  \n",
    "    2. In what year was the book published? (numeric)  \n",
    "    3. (As a list) What is/are the genre(s) of the book? (list of a maximum of 5 genres in the order of their relevance, less are okay too)  \n",
    "    4. Is the female character at any point of the story saved by a male character? (0 = no, 1 = yes)  \n",
    "    5. Does the female character at any point of the story save a male character? (0 = no, 1 = yes)  \n",
    "    6. Is the female character protected by a male character? (0 = no, 1 = yes)  \n",
    "    7. Does the female character protect a male character? (0 = no, 1 = yes)  \n",
    "    8. Is the female character’s problem is solved through help or luck? (0 = no, 1 = yes)  \n",
    "    9. Does the female character solve her own problem through skill? (0 = no, 1 = yes)  \n",
    "    10. Is the female character victimized/harmed by a male character? (0 = no, 1 = yes)  \n",
    "    11. Is the female character a perpetrator or does she harm a male character? (0 = no, 1 = yes)  \n",
    "    12. Does the female character follow orders? (0 = no, 1 = yes)  \n",
    "    13. Does the female character give orders? (0 = no, 1 = yes)  \n",
    "    14. Is the female character admired for her beauty? (0 = no, 1 = yes)  \n",
    "    15. Is the female character admired for her intelligence? (0 = no, 1 = yes)  \n",
    "    16. Is the female character a homemaker? (0 = no, 1 = yes)  \n",
    "    17. Is the female character a breadwinner? (0 = no, 1 = yes)  \n",
    "    18. Is the female character skilled in domestic tasks? (0 = no, 1 = yes)  \n",
    "    19. Is the female character not skilled or uninterested in domestic tasks? (0 = no, 1 = yes)  \n",
    "    20. Does the female character have a lower rank occupation (e.g., nurse, assistant, maid, …)? (0 = no, 1 = yes)  \n",
    "    21. Does the female character have a higher rank occupation (doctor, manager, ruler, …)? (0 = no, 1 = yes)  \n",
    "    22. Is the female character physically weak/incapable? (0 = no, 1 = yes)  \n",
    "    23. Is the female character physically strong/capable? (0 = no, 1 = yes)  \n",
    "    24. Does the female character have low self-esteem/is emotionally fragile? (0 = no, 1 = yes)  \n",
    "    25. Does the female character have high self-esteem/is emotionally strong? (0 = no, 1 = yes)  \n",
    "    26. Is the female character scared of taking risks/challenges? (0 = no, 1 = yes)  \n",
    "    27. Does the female character like taking risks/challenges? (0 = no, 1 = yes)  \n",
    "\n",
    "    If you cannot find information for a female-character-related question, answer the question with a 0.\n",
    "\n",
    "    Example output: \n",
    "    [1, 2015, ['fantasy', 'young adult'], 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1]\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_template = \"\"\"\n",
    "    Please answer the questions defined in your system prompt for the book {title} by {author}.\n",
    "    The female character in question is {fmc_name}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f2425c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify answer format\n",
    "\n",
    "from pydantic import RootModel\n",
    "from typing import List, Literal, Tuple\n",
    "\n",
    "class AnswerFormat(RootModel):\n",
    "    root: Tuple[\n",
    "        Literal[0, 1],  # 1st: 0 or 1\n",
    "        int,            # 2nd: year\n",
    "        List[str],      # 3rd: list of genres or tags\n",
    "        Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1],\n",
    "        Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1],\n",
    "        Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1],\n",
    "        Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1],\n",
    "        Literal[0, 1], Literal[0, 1], Literal[0, 1], Literal[0, 1]\n",
    "    ]  # Total = 27 items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4e68523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   The Mysterious Disappearance of Leon I Mean Noel   \n",
      "1          The Summer I Turned Pretty The Collection   \n",
      "2                        Complete Me Stark Trilogy 3   \n",
      "3          One More Chance Rosemary Beach 8 Chance 2   \n",
      "4                  Sign Off Caught Dead in Wyoming 1   \n",
      "..                                               ...   \n",
      "72     A Song of Ice and Fire series 5Book Boxed Set   \n",
      "73                               The Age of Miracles   \n",
      "74                     London Match Bernard Samson 3   \n",
      "75                       The Eternal Flame Merlin 11   \n",
      "76    The Black Cauldron The Chronicles of Prydain 2   \n",
      "\n",
      "                      author                    fmc_name  \\\n",
      "0              Raskin, Ellen               Mrs. Carillon   \n",
      "1               Han, Jenny *               Belly Conklin   \n",
      "2               Kenner, J. *                       Nikki   \n",
      "3             Glines, Abbi *              Harlow Manning   \n",
      "4         McLinn, Patricia *  Elizabeth 'E. M.' Danniher   \n",
      "..                       ...                         ...   \n",
      "72       Martin, George R.R.          Daenerys Targaryen   \n",
      "73  Walker, Karen Thompson *                       Julia   \n",
      "74             Deighton, Len                Fiona Samson   \n",
      "75            Barron, T.A. *   Elliriyanna Lailoken/Elli   \n",
      "76          Alexander, Lloyd                     Eilonwy   \n",
      "\n",
      "                                            responses  \\\n",
      "0   [1, 1971, [\"mystery\", \"middle grade\"], 0, 0, 0...   \n",
      "1   [1, 2009, [\"young adult\", \"romance\", \"coming-o...   \n",
      "2   [1, 2013, [\"erotic romance\", \"romance\"], 0, 0,...   \n",
      "3   [1, 2014, [\"Romance\", \"New Adult\"], 0, 0, 0, 0...   \n",
      "4   [1, 2012, [\"mystery\", \"fiction\"], 0, 0, 0, 0, ...   \n",
      "..                                                ...   \n",
      "72  [0, 1996, [\"fantasy\", \"epic fantasy\"], 1, 0, 1...   \n",
      "73  [1, 2012, [\"dystopian\", \"young adult\", \"scienc...   \n",
      "74  [0, 1985, [\"spy\", \"thriller\"], 0, 0, 0, 0, 0, ...   \n",
      "75  [0, 2011, [\"fantasy\", \"young adult\"], 0, 0, 0,...   \n",
      "76  [0, 1965, [\"fantasy\", \"young adult\", \"adventur...   \n",
      "\n",
      "                                              sources  is_valid  \n",
      "0   [https://en.wikipedia.org/wiki/The_Mysterious_...     False  \n",
      "1   [https://www.sparknotes.com/lit/the-summer-i-t...     False  \n",
      "2   [https://www.goodreads.com/book/show/18129239-...     False  \n",
      "3   [https://abbiglinesbooks.com/rosemary-beach-se...     False  \n",
      "4   [https://www.goodreads.com/book/show/25879760-...     False  \n",
      "..                                                ...       ...  \n",
      "72  [https://awoiaf.westeros.org/index.php/Daenery...     False  \n",
      "73  [https://en.wikipedia.org/wiki/The_Age_of_Mira...     False  \n",
      "74  [https://www.goodreads.com/book/show/386252.Lo...     False  \n",
      "75  [https://en.wikipedia.org/wiki/Merlin_Book_11:...     False  \n",
      "76  [https://en.wikipedia.org/wiki/Princess_Eilonw...     False  \n",
      "\n",
      "[77 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Setting my API key\n",
    "YOUR_API_KEY = os.environ[\"PERPLEXITY_API_KEY\"]\n",
    "\n",
    "# Saying hi it's me, and this is what I'll be sending\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {YOUR_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# This is where I want to send it to\n",
    "url = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "# I'll store the responses I get in this (as of now, empty) list\n",
    "responses = []\n",
    "\n",
    "# I'll store the citations for each answer in this list\n",
    "citations = []\n",
    "\n",
    "# Setting up what I want to send to Perplexity\n",
    "for index, row in df_fmc.iterrows():\n",
    "    # Extract title and author from each row \n",
    "    title = row[\"title\"]\n",
    "    author = row[\"author\"]\n",
    "    fmc_name = row[\"fmc_name\"]\n",
    "\n",
    "    # Format user prompt with current title and author\n",
    "    user_prompt = user_prompt_template.format(title=title, author=author, fmc_name=fmc_name)\n",
    "\n",
    "    # Payload\n",
    "    payload = {\n",
    "        \"model\": \"sonar\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 2000,\n",
    "        \"temperature\": 0,  # Controls randomness in the response\n",
    "        # \"top_p\": 0.9,\n",
    "        # \"search_domain_filter\": [\"<any>\"],\n",
    "        # \"return_images\": False,\n",
    "        # \"return_related_questions\": False,\n",
    "        # \"search_recency_filter\": \"<string>\",\n",
    "        # \"top_k\": 0,\n",
    "        # \"stream\": False,\n",
    "        # \"presence_penalty\": 0,\n",
    "        # \"frequency_penalty\": 1,\n",
    "        \"response_format\": {\n",
    "          \"type\": \"json_schema\",\n",
    "          \"json_schema\": {\"schema\": AnswerFormat.model_json_schema()},\n",
    "        },\n",
    "        # \"web_search_options\": {\"search_context_size\": \"high\"}\n",
    "    }\n",
    "\n",
    "    # Send the request to the Perplexity API\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    # Check the response\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        # Extract the answer from the response\n",
    "        answer = response_json.get('choices', [{}])[0].get('message', {}).get('content', 'No answer found')\n",
    "        # Extract sources\n",
    "        citation = response_json.get(\"citations\", [])\n",
    "        # Store answer and sources\n",
    "        responses.append(answer)\n",
    "        citations.append(citation)\n",
    "    else:\n",
    "        # Handle errors by appending an error message\n",
    "        responses.append(f\"Error: {response.status_code}\")\n",
    "\n",
    "df_fmc['responses'] = responses\n",
    "df_fmc['sources'] = citations\n",
    "\n",
    "print(df_fmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reponses column is string, convert to list\n",
    "df_fmc[\"responses\"] = df_fmc[\"responses\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4de708ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid rows: 0\n",
      "Empty DataFrame\n",
      "Columns: [title, responses]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def validate_response_format(row):\n",
    "    r = row['responses']\n",
    "\n",
    "    # Check that it's a list and has length 27\n",
    "    if not isinstance(r, list) or len(r) != 27:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # r[0] should be 0 or 1\n",
    "        if r[0] not in [0, 1]:\n",
    "            return False\n",
    "\n",
    "        # r[1] should be an int\n",
    "        if not isinstance(r[1], int):\n",
    "            return False\n",
    "\n",
    "        # r[2] should be a list of strings\n",
    "        if not isinstance(r[2], list):\n",
    "            return False\n",
    "        if not all(isinstance(tag, str) for tag in r[2]):\n",
    "            return False\n",
    "\n",
    "        # r[3:] should all be 0 or 1\n",
    "        if not all(isinstance(x, int) and x in [0, 1] for x in r[3:]):\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Issue in row: {row['title']} — Error: {e}\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "df_fmc['is_valid'] = df_fmc.apply(validate_response_format, axis=1)\n",
    "invalid_rows = df_fmc[~df_fmc['is_valid']]\n",
    "print(f\"Number of invalid rows: {len(invalid_rows)}\")\n",
    "print(invalid_rows[['title', 'responses']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678a9d6",
   "metadata": {},
   "source": [
    "### Cost Overview  \n",
    "**Round 1**\n",
    "* started with $5.03\n",
    "* ran for 77 books\n",
    "* left with $4.83\n",
    "* so $0.2 for 77 books\n",
    "* so $0.26 for 100 books\n",
    "* We'll have around 80% of the original 18027 books, so ~14.421 books\n",
    "* so around $37,45 for all books \n",
    "  \n",
    "**Round 2**\n",
    "* started with $4.12\n",
    "* ran for 77 books\n",
    "* left with $3.63\n",
    "* so $0.49 for 77 books "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "943ce128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame\n",
    "df_fmc.to_csv('df_fmc_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
